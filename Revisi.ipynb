{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "621ec69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import warnings; warnings.simplefilter('ignore')\n",
    "import time\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import cluster\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold #for K-fold cross\n",
    "from sklearn.model_selection import cross_val_score #scoreevaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.under_sampling import NearMiss # underSampling\n",
    "from imblearn.over_sampling import SMOTE # OverSampling\n",
    "from imblearn.combine import SMOTEENN # Combination of the 2\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm, tree, neighbors\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB,BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2917a110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>databersih</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Klarifikasi Terkait Perbedaan Hasil Situng KPU...</td>\n",
       "      <td>klarifikasi kait beda hasil situng kpu pindah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>“PKS dan Gerindra Purwakarta Bantah Pasang Spa...</td>\n",
       "      <td>pks gerindra purwakarta bantah pasang spanduk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Universitas Muhammadiyah Kupang Bantah Akan Me...</td>\n",
       "      <td>universitas muhammadiyah kupang bantah mengini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Klarifikasi Atas Isu OTT Bupati Kapuas Oleh KPK</td>\n",
       "      <td>klarifikasi isu ott bupati kapuas kpk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>“Kronologis Polisi Berondong Sedan Terobos Raz...</td>\n",
       "      <td>kronologis polisi berondong sedan terobos razi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Foto Sekarang malesiya sapu habis penduduk asi...</td>\n",
       "      <td>malesiya sapu habis duduk asing perhati perhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Foto Sekarang malesiya sapu habis penduduk asi...</td>\n",
       "      <td>malesiya sapu habis duduk asing perhati perhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Klarifikasi Polres Bogor Terkait Pembuatan SIM...</td>\n",
       "      <td>klarifikasi polres bogor kait sim tes  150  ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ketua INASGOC Bantah Indonesia Bermain Curang ...</td>\n",
       "      <td>ketua inasgoc bantah indonesia main curang cab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Klarifikasi “Kenapa sholat di tempat ibadah ag...</td>\n",
       "      <td>klarifikasi sholat ibadah agama darurat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Polisi Mengklarifikasi Bahwa Tidak Ada Bom di ...</td>\n",
       "      <td>polisi klarifikasi bom pasuruan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>“Ormas Projo Bantah Keluarkan Surat Aksi Kiri ...</td>\n",
       "      <td>ormas projo bantah surat aksi kiri super senyap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  label                                               text  \\\n",
       "4536         387    0.0  Klarifikasi Terkait Perbedaan Hasil Situng KPU...   \n",
       "4537         388    0.0  “PKS dan Gerindra Purwakarta Bantah Pasang Spa...   \n",
       "4538         389    0.0  Universitas Muhammadiyah Kupang Bantah Akan Me...   \n",
       "4539         390    0.0    Klarifikasi Atas Isu OTT Bupati Kapuas Oleh KPK   \n",
       "4540         391    0.0  “Kronologis Polisi Berondong Sedan Terobos Raz...   \n",
       "4541         392    1.0  Foto Sekarang malesiya sapu habis penduduk asi...   \n",
       "4542         393    1.0  Foto Sekarang malesiya sapu habis penduduk asi...   \n",
       "4543         394    0.0  Klarifikasi Polres Bogor Terkait Pembuatan SIM...   \n",
       "4544         395    0.0  Ketua INASGOC Bantah Indonesia Bermain Curang ...   \n",
       "4545         396    0.0  Klarifikasi “Kenapa sholat di tempat ibadah ag...   \n",
       "4546         397    0.0  Polisi Mengklarifikasi Bahwa Tidak Ada Bom di ...   \n",
       "4547         398    0.0  “Ormas Projo Bantah Keluarkan Surat Aksi Kiri ...   \n",
       "\n",
       "                                             databersih  \n",
       "4536  klarifikasi kait beda hasil situng kpu pindah ...  \n",
       "4537  pks gerindra purwakarta bantah pasang spanduk ...  \n",
       "4538  universitas muhammadiyah kupang bantah mengini...  \n",
       "4539              klarifikasi isu ott bupati kapuas kpk  \n",
       "4540  kronologis polisi berondong sedan terobos razi...  \n",
       "4541  malesiya sapu habis duduk asing perhati perhat...  \n",
       "4542  malesiya sapu habis duduk asing perhati perhat...  \n",
       "4543  klarifikasi polres bogor kait sim tes  150  ac...  \n",
       "4544  ketua inasgoc bantah indonesia main curang cab...  \n",
       "4545            klarifikasi sholat ibadah agama darurat  \n",
       "4546                    polisi klarifikasi bom pasuruan  \n",
       "4547    ormas projo bantah surat aksi kiri super senyap  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv ('dataset.csv')\n",
    "df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8f2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bentuk VSM-nya\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True, smooth_idf= True, sublinear_tf=True, \n",
    "                                   ngram_range=(1, 2), max_df=0.90, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022f0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4548, 13786) 4548\n"
     ]
    }
   ],
   "source": [
    "##TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1, 2))\n",
    "\n",
    "listdata=df['databersih'].values.astype('object')\n",
    "listdata = [d for d in listdata]\n",
    "\n",
    "listdata\n",
    "v = TfidfVectorizer(decode_error='replace', encoding='utf-8')\n",
    "tfidf = v.fit_transform(df['databersih'].values.astype('U'))\n",
    "y = df.iloc[:, 2].values\n",
    "print(tfidf.shape, len(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97830d2b",
   "metadata": {},
   "source": [
    "max_df= 0.9 dan min_df=5 , nilai max_df tersebut artinya kita mengabaikan kata yang muncul lebih dari 90% dokumen dan nilai min_df artinya kita mengabaikan kata yang muncul kurang dari 5 dokumen, tf idf yang didapatkan adalah (4548, 13786) 4548 kalimat dengan 13786 kata unik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3eeeba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3183, 2310)\n",
      "(1365, 2310)\n",
      "(3183,)\n",
      "(1365,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 1\n",
    "X = df['databersih'].values.astype('U')\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "X_train = vectorizer.fit_transform(X_train) # \"Fit_Transform\"\n",
    "X_test = vectorizer.transform(X_test) # Perhatikan disini hanya \"Transform\"\n",
    "\n",
    "#print(X_train.shape, X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfe52d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e9dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi =  0.8227106227106227\n",
      "[[126 212]\n",
      " [ 30 997]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.37      0.51       338\n",
      "         1.0       0.82      0.97      0.89      1027\n",
      "\n",
      "    accuracy                           0.82      1365\n",
      "   macro avg       0.82      0.67      0.70      1365\n",
      "weighted avg       0.82      0.82      0.80      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "dSVM = svm.SVC( kernel = 'linear')\n",
    "dSVM.fit(X_train, y_train)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(y_test, y_SVM))\n",
    "print(confusion_matrix(y_test, y_SVM))\n",
    "print(classification_report(y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e185121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderSamplingResults:\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.50      0.65      0.78      0.56      0.71      0.50       338\n",
      "        1.0       0.87      0.78      0.65      0.83      0.71      0.52      1027\n",
      "\n",
      "avg / total       0.78      0.75      0.68      0.76      0.71      0.51      1365\n",
      "\n",
      "Akurasi undersampling test=  0.7516483516483516\n"
     ]
    }
   ],
   "source": [
    "#under sampling\n",
    "rm = RandomUnderSampler(random_state=1)\n",
    "X_rm, y_rm = rm.fit_resample(X_train, y_train)\n",
    "dSVM = svm.SVC( kernel = 'linear')\n",
    "dSVM.fit(X_rm, y_rm)\n",
    "y_dSVM = dSVM.predict(X_test); del dSVM\n",
    "print('UnderSamplingResults:\\n',classification_report_imbalanced(y_test, y_dSVM))\n",
    "print('Akurasi undersampling test= ', accuracy_score(y_test,y_dSVM))\n",
    "#print(classification_report(y_test, y_dSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a20d2d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverSamplingResults:\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.55      0.58      0.84      0.56      0.70      0.47       338\n",
      "        1.0       0.86      0.84      0.58      0.85      0.70      0.50      1027\n",
      "\n",
      "avg / total       0.78      0.78      0.64      0.78      0.70      0.49      1365\n",
      "\n",
      "Akurasi oversampling test =  0.7772893772893773\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "dSVM = svm.SVC( kernel = 'linear')\n",
    "dSVM.fit(X_ros, y_ros)\n",
    "y_dSVM = dSVM.predict(X_test); del dSVM\n",
    "print('OverSamplingResults:\\n',classification_report_imbalanced(y_test, y_dSVM))\n",
    "print('Akurasi oversampling test = ', accuracy_score(y_test,y_dSVM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8635fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinationResults:\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.50      0.65      0.78      0.56      0.71      0.50       338\n",
      "        1.0       0.87      0.78      0.65      0.83      0.71      0.52      1027\n",
      "\n",
      "avg / total       0.78      0.75      0.68      0.76      0.71      0.51      1365\n",
      "\n",
      "Akurasi combination =  0.7516483516483516\n"
     ]
    }
   ],
   "source": [
    "#both\n",
    "#smt = SMOTEENN (ratio='auto')\n",
    "smt = SMOTEENN(random_state=1)\n",
    "X_smt, y_smt = smt.fit_resample(X_train, y_train)\n",
    "dSVM = svm.SVC( kernel = 'linear')\n",
    "dSVM.fit(X_rm, y_rm)\n",
    "y_dSVM = dSVM.predict(X_test); del dSVM\n",
    "print('CombinationResults:\\n',classification_report_imbalanced(y_test, y_dSVM))\n",
    "print('Akurasi combination = ', accuracy_score(y_test, y_dSVM))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b07196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinationResults:\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.50      0.63      0.79      0.55      0.70      0.49       338\n",
      "        1.0       0.87      0.79      0.63      0.83      0.70      0.50      1027\n",
      "\n",
      "avg / total       0.77      0.75      0.67      0.76      0.70      0.50      1365\n",
      "\n",
      "Akurasi combination =  0.7501831501831502\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smot = SMOTE(sampling_strategy='all')\n",
    "X_smot, y_smot = smot.fit_resample(X_train, y_train)\n",
    "dSVM = svm.SVC( kernel = 'linear')\n",
    "dSVM.fit(X_smot, y_smot)\n",
    "y_dSVM = dSVM.predict(X_test); del dSVM\n",
    "print('CombinationResults:\\n',classification_report_imbalanced(y_test, y_dSVM))\n",
    "print('Akurasi combination = ', accuracy_score(y_test, y_dSVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd200fe4",
   "metadata": {},
   "source": [
    "# Reglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0b072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212454212454212\n",
      "[[ 105  233]\n",
      " [  11 1016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.31      0.46       338\n",
      "         1.0       0.81      0.99      0.89      1027\n",
      "\n",
      "    accuracy                           0.82      1365\n",
      "   macro avg       0.86      0.65      0.68      1365\n",
      "weighted avg       0.84      0.82      0.79      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logreg = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\")\n",
    "model_logreg.fit(X_train, y_train)\n",
    "Y_pred = model_logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(Y_pred, y_test))\n",
    "print(confusion_matrix(y_test, Y_pred))\n",
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a744a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderSamplingResults:\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.53      0.64      0.81      0.58      0.73      0.52       338\n",
      "        1.0       0.87      0.81      0.64      0.84      0.73      0.53      1027\n",
      "\n",
      "avg / total       0.79      0.77      0.69      0.78      0.73      0.53      1365\n",
      "\n",
      "Akurasi undersampling test=  0.7728937728937729\n"
     ]
    }
   ],
   "source": [
    "#under sampling\n",
    "rm = RandomUnderSampler(random_state=1)\n",
    "X_rm, y_rm = rm.fit_resample(X_train, y_train)\n",
    "model_logreg = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\")\n",
    "model_logreg.fit(X_rm, y_rm)\n",
    "y_model_logreg = model_logreg.predict(X_test); del model_logreg\n",
    "print('UnderSamplingResults:\\n',classification_report_imbalanced(y_test, y_model_logreg))\n",
    "print('Akurasi undersampling test= ', accuracy_score(y_test,y_model_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f647e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8175824175824176\n",
      "[[155 183]\n",
      " [ 66 961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.46      0.55       338\n",
      "         1.0       0.84      0.94      0.89      1027\n",
      "\n",
      "    accuracy                           0.82      1365\n",
      "   macro avg       0.77      0.70      0.72      1365\n",
      "weighted avg       0.81      0.82      0.80      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_rf))\n",
    "print(confusion_matrix(y_test, y_rf))\n",
    "print(classification_report(y_test, y_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215591d",
   "metadata": {},
   "source": [
    "# Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3ed4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
